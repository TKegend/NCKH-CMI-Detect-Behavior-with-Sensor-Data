{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034ebc83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:24:57.471329Z",
     "iopub.status.busy": "2025-10-19T08:24:57.470973Z",
     "iopub.status.idle": "2025-10-19T08:25:15.593609Z",
     "shell.execute_reply": "2025-10-19T08:25:15.592139Z"
    },
    "papermill": {
     "duration": 18.13228,
     "end_time": "2025-10-19T08:25:15.595839",
     "exception": false,
     "start_time": "2025-10-19T08:24:57.463559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import joblib\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ML utilities\n",
    "from sklearn.model_selection import StratifiedGroupKFold, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# World coordinate transformation\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Competition specific\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "print(\"✓ All imports loaded successfully\")\n",
    "class Config: \n",
    "    \"\"\"Central configuration class for training and data parameters\"\"\"\n",
    "    \n",
    "    # Paths for Kaggle environment\n",
    "    EXPORT_DIR = \"/kaggle/input/lstm-triet\"\n",
    "    TRAIN_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\"\n",
    "    TEST_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\"\n",
    "    TEST_DEMOGRAPHICS_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\"\n",
    "    \n",
    "    # Training parameters\n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # Feature columns\n",
    "    ACC_COLS = ['acc_x', 'acc_y', 'acc_z']\n",
    "    ROT_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    THM_COLS = ['thm_1', 'thm_2', 'thm_3', 'thm_4', \"thm_5\"]\n",
    "    \n",
    "   \n",
    "\n",
    "# Set reproducibility\n",
    "np.random.seed(Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f8a04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.607361Z",
     "iopub.status.busy": "2025-10-19T08:25:15.606641Z",
     "iopub.status.idle": "2025-10-19T08:25:15.614509Z",
     "shell.execute_reply": "2025-10-19T08:25:15.613258Z"
    },
    "papermill": {
     "duration": 0.0154,
     "end_time": "2025-10-19T08:25:15.616390",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.600990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GESTURE_MAPPER = {\n",
    "    \"Above ear - pull hair\": 0,\n",
    "    \"Cheek - pinch skin\": 1,\n",
    "    \"Eyebrow - pull hair\": 2,\n",
    "    \"Eyelash - pull hair\": 3, \n",
    "    \"Forehead - pull hairline\": 4,\n",
    "    \"Forehead - scratch\": 5,\n",
    "    \"Neck - pinch skin\": 6, \n",
    "    \"Neck - scratch\": 7,\n",
    "    \n",
    "    \"Drink from bottle/cup\": 8,\n",
    "    \"Feel around in tray and pull out an object\": 9,\n",
    "    \"Glasses on/off\": 10,\n",
    "    \"Pinch knee/leg skin\": 11, \n",
    "    \"Pull air toward your face\": 12,\n",
    "    \"Scratch knee/leg skin\": 13,\n",
    "    \"Text on phone\": 14,\n",
    "    \"Wave hello\": 15,\n",
    "    \"Write name in air\": 16,\n",
    "    \"Write name on leg\": 17,\n",
    "}\n",
    "\n",
    "REVERSE_GESTURE_MAPPER = {v: k for k, v in GESTURE_MAPPER.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e10287b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.627515Z",
     "iopub.status.busy": "2025-10-19T08:25:15.627152Z",
     "iopub.status.idle": "2025-10-19T08:25:15.659308Z",
     "shell.execute_reply": "2025-10-19T08:25:15.658140Z"
    },
    "papermill": {
     "duration": 0.040203,
     "end_time": "2025-10-19T08:25:15.661539",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.621336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction), nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualSEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=\"same\", bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=\"same\", bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.se = SEBlock(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        ) if in_channels != out_channels else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.se(self.bn2(self.conv2(out)))\n",
    "        out = self.dropout(self.pool(self.relu(out + identity)))\n",
    "        return out\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim): super().__init__(); self.attn = nn.Sequential(nn.Linear(hidden_dim, 1), nn.Tanh())\n",
    "    def forward(self, x):\n",
    "        weights = F.softmax(self.attn(x).squeeze(-1), dim=1).unsqueeze(-1)\n",
    "        return torch.sum(x * weights, dim=1)\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, feature_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = feature_dim // num_heads\n",
    "        assert feature_dim % num_heads == 0, \"feature_dim must be divisible by num_heads\"\n",
    "        self.q_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.k_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.v_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.out_linear = nn.Linear(feature_dim, feature_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(feature_dim)\n",
    "    def forward(self, query_branch, key_value_branches):\n",
    "        B, T, C = query_branch.shape\n",
    "        Q = self.q_linear(query_branch)\n",
    "        all_kv = torch.cat(key_value_branches, dim=1)\n",
    "        K = self.k_linear(all_kv)\n",
    "        V = self.v_linear(all_kv)\n",
    "        Q = Q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(B, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(B, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        attn_output = torch.matmul(attn_weights, V)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        output = self.out_linear(attn_output)\n",
    "        output = self.layer_norm(query_branch + output)\n",
    "        return output\n",
    "\n",
    "class IMUCrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, feature_dim=256, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.cross_attn1 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "        self.cross_attn2 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "        self.cross_attn3 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "    def forward(self, imu1, imu2, imu3):\n",
    "        e1 = self.cross_attn1(imu1, [imu2, imu3])\n",
    "        e2 = self.cross_attn2(imu2, [imu1, imu3])\n",
    "        e3 = self.cross_attn3(imu3, [imu1, imu2])\n",
    "        return e1, e2, e3\n",
    "\n",
    "class IMUCrossAttentionModel(nn.Module):\n",
    "    def __init__(self, imu_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.imu_dim = imu_dim\n",
    "        # 3 nhánh CNN cho IMU\n",
    "        self.imu_branch1 = nn.Sequential(ResidualSEBlock(12, 128, 3), ResidualSEBlock(128, 256, 5))\n",
    "        self.imu_branch2 = nn.Sequential(ResidualSEBlock(11, 128, 3), ResidualSEBlock(128, 256, 5))\n",
    "        self.imu_branch3 = nn.Sequential(ResidualSEBlock(12, 128, 3), ResidualSEBlock(128, 256, 5))\n",
    "        self.cross_attention_fusion = IMUCrossAttentionFusion(feature_dim=256)\n",
    "        self.bilstm = nn.LSTM(256*3, 512, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.attention = AttentionLayer(1024)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 512, bias=False), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256, bias=False), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        features = self.extract_features(x)  # call shared feature extractor\n",
    "        out = self.fc_layers(features)\n",
    "        return out\n",
    "        \n",
    "    def extract_features(self, x):\n",
    "        imu = x[:, :, :self.imu_dim]\n",
    "        imu1 = self.imu_branch1(imu[:, :, :12].transpose(1, 2)).transpose(1, 2)\n",
    "        imu2 = self.imu_branch2(imu[:, :, 12:23].transpose(1, 2)).transpose(1, 2)\n",
    "        imu3 = self.imu_branch3(imu[:, :, 23:].transpose(1, 2)).transpose(1, 2)\n",
    "        imu1, imu2, imu3 = self.cross_attention_fusion(imu1, imu2, imu3)\n",
    "        merged = torch.cat((imu1, imu2, imu3), dim=2)\n",
    "        lstm_out, _ = self.bilstm(merged)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        attended = self.attention(lstm_out)\n",
    "        return attended  # shape: (batch_size, 1024)\n",
    "\n",
    "class ModelEMA(nn.Module):\n",
    "    def __init__(self, model, decay=0.99, device=None):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        if self.device:\n",
    "            self.module.to(device=device)\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(), model.state_dict().values()):\n",
    "                if self.device:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "    def update(self, model): self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "    def set(self, model): self._update(model, update_fn=lambda e, m: m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c35e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.673187Z",
     "iopub.status.busy": "2025-10-19T08:25:15.672881Z",
     "iopub.status.idle": "2025-10-19T08:25:15.680666Z",
     "shell.execute_reply": "2025-10-19T08:25:15.679491Z"
    },
    "papermill": {
     "duration": 0.015445,
     "end_time": "2025-10-19T08:25:15.682275",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.666830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_world_acceleration(acc: np.ndarray, rot: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert acceleration from device coordinates to world coordinates\n",
    "    \n",
    "    This is the key innovation: normalizing for device orientation\n",
    "    \n",
    "    Args:\n",
    "        acc: acceleration in device coordinates, shape (time_steps, 3) [x, y, z]\n",
    "        rot: rotation quaternion, shape (time_steps, 4) [w, x, y, z] (normalized)\n",
    "    \n",
    "    Returns:\n",
    "        acc_world: acceleration in world coordinates, shape (time_steps, 3)\n",
    "        \n",
    "    Why this matters:\n",
    "    - Device acceleration depends on how the watch is oriented on the wri/st\n",
    "    - World acceleration is independent of device orientation\n",
    "    - This helps the model focus on actual hand motion rather than wrist rotation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert quaternion format from [w, x, y, z] to [x, y, z, w] for scipy\n",
    "        rot_scipy = rot[:, [1, 2, 3, 0]]\n",
    "        \n",
    "        # Verify quaternions are valid (non-zero norm)\n",
    "        norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "        if np.any(norms < 1e-8):\n",
    "            # Replace problematic quaternions with identity\n",
    "            mask = norms < 1e-8\n",
    "            rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n",
    "        \n",
    "        # Create rotation object and apply transformation\n",
    "        r = R.from_quat(rot_scipy)\n",
    "        acc_world = r.apply(acc)\n",
    "        \n",
    "    except Exception:\n",
    "        # Fallback to original acceleration if transformation fails\n",
    "        print(\"Warning: World coordinate transformation failed, using device coordinates\")\n",
    "        acc_world = acc.copy()\n",
    "    \n",
    "    return acc_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8afe56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.693036Z",
     "iopub.status.busy": "2025-10-19T08:25:15.692726Z",
     "iopub.status.idle": "2025-10-19T08:25:15.701273Z",
     "shell.execute_reply": "2025-10-19T08:25:15.700012Z"
    },
    "papermill": {
     "duration": 0.016054,
     "end_time": "2025-10-19T08:25:15.703182",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.687128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bỏ gia tốc trọng trường\n",
    "def remove_gravity_from_acc(acc_data: np.ndarray, rot_data: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e462f4f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.713624Z",
     "iopub.status.busy": "2025-10-19T08:25:15.713242Z",
     "iopub.status.idle": "2025-10-19T08:25:15.721368Z",
     "shell.execute_reply": "2025-10-19T08:25:15.720198Z"
    },
    "papermill": {
     "duration": 0.015331,
     "end_time": "2025-10-19T08:25:15.723175",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.707844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tính vận tốc quay\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da56a7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.733509Z",
     "iopub.status.busy": "2025-10-19T08:25:15.733186Z",
     "iopub.status.idle": "2025-10-19T08:25:15.741899Z",
     "shell.execute_reply": "2025-10-19T08:25:15.740736Z"
    },
    "papermill": {
     "duration": 0.015829,
     "end_time": "2025-10-19T08:25:15.743675",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.727846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2abd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.754039Z",
     "iopub.status.busy": "2025-10-19T08:25:15.753718Z",
     "iopub.status.idle": "2025-10-19T08:25:15.763298Z",
     "shell.execute_reply": "2025-10-19T08:25:15.762296Z"
    },
    "papermill": {
     "duration": 0.016793,
     "end_time": "2025-10-19T08:25:15.765045",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.748252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle missing values in quaternion data intelligently\n",
    "    \n",
    "    Key insight: Quaternions must have unit length |q| = 1\n",
    "    If one component is missing, we can reconstruct it from the others\n",
    "    \"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            # No missing values, normalize to unit quaternion\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]  # Identity quaternion\n",
    "                \n",
    "        elif missing_count == 1:\n",
    "            # One missing value, reconstruct using unit quaternion constraint\n",
    "            # |w|² + |x|² + |y|² + |z|² = 1\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            \n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                # Choose sign for continuity with previous quaternion\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            # More than one missing value, use identity quaternion\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc79c9de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.775579Z",
     "iopub.status.busy": "2025-10-19T08:25:15.775242Z",
     "iopub.status.idle": "2025-10-19T08:25:15.783863Z",
     "shell.execute_reply": "2025-10-19T08:25:15.782857Z"
    },
    "papermill": {
     "duration": 0.015731,
     "end_time": "2025-10-19T08:25:15.785585",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.769854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mirror_quaternion(quat):\n",
    "    \"\"\"\n",
    "    Mirror a single quaternion through the YZ plane.\n",
    "\n",
    "    Args:\n",
    "        quat (array of shape (N, 4)): [w, x, y, z]\n",
    "\n",
    "    Returns:\n",
    "        mirrored (np.ndarray of shape (N, 4)): mirrored quaternion [w, x, y, z]\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.diag([-1, 1, 1])  # reflection through YZ\n",
    "    rot = R.from_quat(quat[:, [1, 2, 3, 0]])  # SciPy uses [x, y, z, w]\n",
    "    R_mat = rot.as_matrix()\n",
    "    R_flipped = P @ R_mat @ P\n",
    "    flipped = R.from_matrix(R_flipped).as_quat()\n",
    "    return flipped[:, [3, 0, 1, 2]]  # back to [w, x, y, z]\n",
    "\n",
    "\n",
    "def mirror_data(data):\n",
    "    \"\"\"\n",
    "    Mirror left-handed samples to match right-handed frame.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray of shape (N, 7)): sensor data\n",
    "    \n",
    "    Returns:\n",
    "        A new array with mirrored left-handed samples.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data[:, 0] = -data[:, 0]\n",
    "    data[:, 3:] = mirror_quaternion(data[:, 3:]) # [w, x, y, z]\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_left_handed(df, dem):\n",
    "    \n",
    "    left_handed = dem[dem[\"handedness\"] == 0]\n",
    "    left_handed = df.loc[df[\"subject\"].isin(left_handed[\"subject\"])]\n",
    "    cols_to_transform = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "    left_handed_arr = left_handed[cols_to_transform].to_numpy()\n",
    "    df.loc[df[\"subject\"].isin(left_handed[\"subject\"]), cols_to_transform] = mirror_data(left_handed_arr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888bc616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.797002Z",
     "iopub.status.busy": "2025-10-19T08:25:15.796600Z",
     "iopub.status.idle": "2025-10-19T08:25:15.816614Z",
     "shell.execute_reply": "2025-10-19T08:25:15.815543Z"
    },
    "papermill": {
     "duration": 0.027883,
     "end_time": "2025-10-19T08:25:15.818262",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.790379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"acc_mag\"] = np.linalg.norm(df[Config.ACC_COLS].values, axis=1)\n",
    "    df[\"acc_mag_jerk\"] = df.groupby(\"sequence_id\")[\"acc_mag\"].diff().fillna(0)\n",
    "    df[\"jerk_x\"], df[\"jerk_y\"], df[\"jerk_z\"] = np.gradient(df[\"acc_x\"]), np.gradient(df[\"acc_y\"]), np.gradient(df[\"acc_z\"])\n",
    "    df[\"jerk_magnitude\"] = np.linalg.norm(df[[\"jerk_x\", \"jerk_y\", \"jerk_z\"]].values, axis=1)\n",
    "\n",
    "    window = 20\n",
    "    for _, g in df.groupby(\"sequence_id\"):\n",
    "        df.loc[g.index, \"acc_xy_corr\"] = g[\"acc_x\"].rolling(window, min_periods=1).corr(g[\"acc_y\"]).fillna(0)\n",
    "        df.loc[g.index, \"acc_xz_corr\"] = g[\"acc_x\"].rolling(window, min_periods=1).corr(g[\"acc_z\"]).fillna(0)\n",
    "        df.loc[g.index, \"acc_yz_corr\"] = g[\"acc_y\"].rolling(window, min_periods=1).corr(g[\"acc_z\"]).fillna(0)\n",
    "\n",
    "    df[\"rot_angle\"] = 2 * np.arccos(df[\"rot_w\"].clip(-1, 1))\n",
    "    df[\"rot_angle_vel\"] = df.groupby(\"sequence_id\")[\"rot_angle\"].diff().fillna(0)\n",
    "\n",
    "    rot_numpy = df[Config.ROT_COLS].to_numpy()\n",
    "    angular_vel = calculate_angular_velocity_from_quat(rot_numpy)\n",
    "    angular_dist = calculate_angular_distance(rot_numpy)\n",
    "    df[[\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]] = angular_vel\n",
    "    df[\"angular_distance\"] = angular_dist\n",
    "    df[\"angular_vel_magnitude\"] = np.linalg.norm(angular_vel, axis=1)\n",
    "\n",
    "    linear_accel = remove_gravity_from_acc(df[Config.ACC_COLS], df[Config.ROT_COLS])\n",
    "    df[[\"acc_x2\", \"acc_y2\", \"acc_z2\"]] = linear_accel\n",
    "    df[\"acc_mag2\"] = np.linalg.norm(linear_accel, axis=1)\n",
    "    df[\"acc_mag_jerk2\"] = df.groupby(\"sequence_id\")[\"acc_mag2\"].diff().fillna(0)\n",
    "    df[\"jerk_x2\"], df[\"jerk_y2\"], df[\"jerk_z2\"] = np.gradient(df[\"acc_x2\"]), np.gradient(df[\"acc_y2\"]), np.gradient(df[\"acc_z2\"])\n",
    "    df[\"jerk_magnitude2\"] = np.linalg.norm(df[[\"jerk_x2\", \"jerk_y2\", \"jerk_z2\"]].values, axis=1)\n",
    "\n",
    "    for _, g in df.groupby(\"sequence_id\"):\n",
    "        df.loc[g.index, \"acc_xy_corr2\"] = g[\"acc_x2\"].rolling(window, min_periods=1).corr(g[\"acc_y2\"]).fillna(0)\n",
    "        df.loc[g.index, \"acc_xz_corr2\"] = g[\"acc_x2\"].rolling(window, min_periods=1).corr(g[\"acc_z2\"]).fillna(0)\n",
    "        df.loc[g.index, \"acc_yz_corr2\"] = g[\"acc_y2\"].rolling(window, min_periods=1).corr(g[\"acc_z2\"]).fillna(0)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def pad_sequences(sequences: list, maxlen: int, padding: str=\"pre\", truncating: str=\"pre\", dtype: str=\"float32\") -> np.ndarray:\n",
    "    n_samples = len(sequences)\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "    x = np.zeros((n_samples, maxlen) + sample_shape, dtype=dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        s_np = np.asarray(s, dtype=dtype)\n",
    "        if truncating == \"pre\":\n",
    "            s_np = s_np[-maxlen:]\n",
    "        else:\n",
    "            s_np = s_np[:maxlen]\n",
    "        trunc = s_np.shape[0]\n",
    "        if padding == \"pre\":\n",
    "            x[idx, -trunc:] = s_np\n",
    "        else:\n",
    "            x[idx, :trunc] = s_np\n",
    "    return x\n",
    "\n",
    "def to_categorical(y, num_classes=None):\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "def preprocess_left_handed_pd(df_pd: pd.DataFrame, demo_pd: pd.DataFrame) -> pd.DataFrame:\n",
    "    pl_df = pl.DataFrame(df_pd)\n",
    "    pl_demo = pl.DataFrame(demo_pd)\n",
    "    l_subjs = pl_demo.filter(pl.col(\"handedness\") == 0)[\"subject\"].to_list()\n",
    "    r_tr = pl_df.filter(~pl.col(\"subject\").is_in(l_subjs))\n",
    "    l_tr = pl_df.filter(pl.col(\"subject\").is_in(l_subjs))\n",
    "    if l_tr.shape[0] == 0:\n",
    "        return r_tr.to_pandas()\n",
    "\n",
    "    l_tr = l_tr.with_columns(-pl.col(\"acc_y\"))\n",
    "    l_tr = l_tr.with_columns(-pl.col(\"acc_z\"))\n",
    "    rot_np = l_tr.select(Config.ROT_COLS).to_numpy()\n",
    "    rot_scipy = rot_np[:, [1, 2, 3, 0]]\n",
    "    r = R.from_quat(rot_scipy)\n",
    "    tmp = r.as_euler(\"xyz\")\n",
    "    tmp[:, 1] = -tmp[:, 1]\n",
    "    tmp[:, 2] = -tmp[:, 2]\n",
    "    r = R.from_euler(\"xyz\", tmp)\n",
    "    tmp = r.as_quat()\n",
    "    l_tr = l_tr.with_columns(pl.DataFrame(tmp, schema=[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]))\n",
    "    pl_df2 = pl.concat([r_tr, l_tr]).sort(by=\"row_id\")\n",
    "    return pl_df2.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42ea74d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.830124Z",
     "iopub.status.busy": "2025-10-19T08:25:15.829801Z",
     "iopub.status.idle": "2025-10-19T08:25:15.847064Z",
     "shell.execute_reply": "2025-10-19T08:25:15.845942Z"
    },
    "papermill": {
     "duration": 0.02503,
     "end_time": "2025-10-19T08:25:15.848968",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.823938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_comprehensive_features(sequence: pl.DataFrame, demographics: pl.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract features from IMU data with world acceleration transformation\n",
    "    \n",
    "    Feature Groups:\n",
    "    1. Device Acceleration (acc_x, acc_y, acc_z) - raw sensor data\n",
    "    2. Rotation Quaternion (rot_w, rot_x, rot_y, rot_z) - device orientation  \n",
    "    3. World Acceleration (NEW) - orientation-normalized acceleration\n",
    "    4. Demographics - subject characteristics\n",
    "    5. Sequence metadata - length, etc.\n",
    "    \"\"\"\n",
    "    seq_df = sequence.to_pandas()\n",
    "    demo_df = demographics.to_pandas()\n",
    "    \n",
    "    # Convert to pandas for processing\n",
    "    seq_df = sequence.to_pandas()\n",
    "    demo_df = demographics.to_pandas()\n",
    "    \n",
    "    rot_data = seq_df[Config.ROT_COLS].copy()\n",
    "    rot_data = rot_data.ffill().bfill()\n",
    "    rot_data_clean = handle_quaternion_missing_values(rot_data.values)\n",
    "    \n",
    "    seq_df[Config.ROT_COLS] = rot_data_clean\n",
    "    \n",
    "    if len(demo_df) > 0 and demo_df.iloc[0].get(\"handedness\", 1) == 0:\n",
    "        seq_df = process_left_handed(seq_df, demo_df)\n",
    "   \n",
    "\n",
    "     # Handle missing values in basic sensor data\n",
    "    acc_data = seq_df[Config.ACC_COLS].copy()\n",
    "    acc_data = acc_data.ffill().bfill().fillna(0)\n",
    "\n",
    "    rot_data = seq_df[Config.ROT_COLS].copy()\n",
    "    rot_data = rot_data.ffill().bfill()\n",
    "    rot_data_clean = handle_quaternion_missing_values(rot_data.values)\n",
    "\n",
    "    # rot_data_clean = seq_df[Config.ROT_COLS].copy()\n",
    "\n",
    "    #linear acc\n",
    "    try:\n",
    "        acc_gravity_removed = remove_gravity_from_acc(acc_data.values, rot_data_clean)\n",
    "        # print(\"✓ Gravity remove successfully\")  # Reduced verbosity\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Gravity remove failed: {e}\")\n",
    "        acc_gravity_removed = acc_data.values.copy()  # Fallback to device coordinates\n",
    "\n",
    "    #linear world acc\n",
    "    try:\n",
    "        world_acc_data = compute_world_acceleration(acc_gravity_removed, rot_data_clean)\n",
    "        # print(\"✓ World acceleration computed successfully\")  # Reduced verbosity\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: World acceleration computation failed: {e}\")\n",
    "        world_acc_data = acc_gravity_removed.values.copy()  # Fallback to device coordinates  \n",
    "\n",
    "    #angular velocity\n",
    "    try:\n",
    "        angular_velocity = calculate_angular_velocity_from_quat(rot_data_clean, time_delta=1/200)\n",
    "        # print(\"✓ Calculate angular velocity successfully\")  # Reduced verbosity\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Calculate angular velocity failed: {e}\")\n",
    "        angular_velocity = rot_data.values.copy()  # Fallback to device coordinates\n",
    "\n",
    "    #angular distance\n",
    "    try:\n",
    "        angular_distance = calculate_angular_distance(rot_data_clean)\n",
    "        # print(\"✓ Calculate angular distance successfully\")  # Reduced verbosity\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Calculate angular distance failed: {e}\")\n",
    "        angular_distance = rot_data.values.copy()  # Fallback to device coordinates\n",
    "    \n",
    "    # Initialize feature dictionary\n",
    "    features = {}\n",
    "    \n",
    "    # Add sequence metadata\n",
    "    features['sequence_length'] = len(seq_df)\n",
    "    \n",
    "    # Add demographics features\n",
    "    if len(demo_df) > 0:\n",
    "        demo_row = demo_df.iloc[0]\n",
    "        features['age'] = demo_row.get('age', 0)\n",
    "        features['adult_child'] = demo_row.get('adult_child', 0)\n",
    "        features['sex'] = demo_row.get('sex', 0)\n",
    "        features['handedness'] = demo_row.get('handedness', 0)\n",
    "        features['height_cm'] = demo_row.get('height_cm', 0)\n",
    "        features['shoulder_to_wrist_cm'] = demo_row.get('shoulder_to_wrist_cm', 0)\n",
    "        features['elbow_to_wrist_cm'] = demo_row.get('elbow_to_wrist_cm', 0)\n",
    "    \n",
    "    # Define feature arrays for statistical extraction\n",
    "    feature_arrays = {\n",
    "        'acc': acc_data.values,           # Device acceleration (3D)\n",
    "        'rot': rot_data_clean,            # Rotation quaternion (4D) \n",
    "        'world_acc': world_acc_data,      # World acceleration (3D) - KEY INNOVATION\n",
    "        'acc_g_remove': acc_gravity_removed,\n",
    "        'ang_vel': angular_velocity,\n",
    "        'ang_dis': angular_distance,\n",
    "    }\n",
    "    \n",
    "    # Extract statistical features for each data source\n",
    "    for source_name, array in feature_arrays.items():\n",
    "        if array.ndim == 1:\n",
    "            array = array.reshape(-1, 1)\n",
    "        \n",
    "        n_features = array.shape[1]\n",
    "        \n",
    "        for feat_idx in range(n_features):\n",
    "            feat_data = array[:, feat_idx]\n",
    "            \n",
    "            # Create feature name\n",
    "            if source_name == 'acc':\n",
    "                axis_names = ['x', 'y', 'z']\n",
    "                prefix = f\"acc_{axis_names[feat_idx]}\"\n",
    "            elif source_name == 'rot':\n",
    "                comp_names = ['w', 'x', 'y', 'z']\n",
    "                prefix = f\"rot_{comp_names[feat_idx]}\"\n",
    "            elif source_name == 'world_acc':\n",
    "                axis_names = ['x', 'y', 'z']  \n",
    "                prefix = f\"world_acc_{axis_names[feat_idx]}\"\n",
    "            else:\n",
    "                prefix = f\"{source_name}_{feat_idx}\" if n_features > 1 else source_name\n",
    "            \n",
    "            # Extract comprehensive statistical features\n",
    "            features.update(extract_statistical_features(feat_data, prefix))\n",
    "    \n",
    "    # Compute magnitude features (important for motion intensity)\n",
    "    acc_magnitude = np.linalg.norm(acc_data.values, axis=1)\n",
    "    features.update(extract_statistical_features(acc_magnitude, 'acc_magnitude_raw'))\n",
    "\n",
    "    # Compute linear_acc_magnitude\n",
    "    linear_acc_magnitude = np.linalg.norm(acc_gravity_removed, axis=1)\n",
    "    features.update(extract_statistical_features(linear_acc_magnitude, 'linear_acc_magnitude'))\n",
    "\n",
    "    world_acc_magnitude = np.linalg.norm(world_acc_data, axis=1)\n",
    "    features.update(extract_statistical_features(world_acc_magnitude, 'world_acc_magnitude'))\n",
    "    \n",
    "    # Cross-feature: difference between device and world acceleration magnitudes\n",
    "    # This captures how much device orientation affects motion measurement\n",
    "    acc_world_diff = linear_acc_magnitude - world_acc_magnitude\n",
    "    features.update(extract_statistical_features(acc_world_diff, 'acc_world_diff'))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    result_df = pd.DataFrame([features])\n",
    "    \n",
    "    # Handle any remaining NaN values\n",
    "    result_df = result_df.fillna(0)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aeb128a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.860522Z",
     "iopub.status.busy": "2025-10-19T08:25:15.860178Z",
     "iopub.status.idle": "2025-10-19T08:25:15.880781Z",
     "shell.execute_reply": "2025-10-19T08:25:15.879677Z"
    },
    "papermill": {
     "duration": 0.02846,
     "end_time": "2025-10-19T08:25:15.882646",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.854186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_statistical_features(data: np.ndarray, prefix: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract comprehensive statistical features from a 1D time series\n",
    "    \n",
    "    Returns features that capture:\n",
    "    - Central tendency: mean, median, mode region\n",
    "    - Spread: std, variance, range, IQR  \n",
    "    - Shape: skewness, kurtosis\n",
    "    - Dynamics: differences, trends, changes\n",
    "    - Segments: beginning vs middle vs end behavior\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    features[f'{prefix}_mean'] = np.mean(data)\n",
    "    features[f'{prefix}_std'] = np.std(data)\n",
    "    features[f'{prefix}_var'] = np.var(data)\n",
    "    features[f'{prefix}_min'] = np.min(data)\n",
    "    features[f'{prefix}_max'] = np.max(data)\n",
    "    features[f'{prefix}_median'] = np.median(data)\n",
    "    features[f'{prefix}_q25'] = np.percentile(data, 25)\n",
    "    features[f'{prefix}_q75'] = np.percentile(data, 75)\n",
    "    features[f'{prefix}_iqr'] = np.percentile(data, 75) - np.percentile(data, 25)\n",
    "    features[f'{prefix}_mean_abs'] = np.abs(data).mean()\n",
    "    features[f'{prefix}_rms'] = np.sqrt((data**2).mean())\n",
    "    \n",
    "    # Range and boundary features\n",
    "    features[f'{prefix}_range'] = np.max(data) - np.min(data)\n",
    "    features[f'{prefix}_first'] = data[0] if len(data) > 0 else 0\n",
    "    features[f'{prefix}_last'] = data[-1] if len(data) > 0 else 0\n",
    "    features[f'{prefix}_delta'] = data[-1] - data[0] if len(data) > 0 else 0\n",
    "    \n",
    "    # Higher order moments (shape of distribution)\n",
    "    if len(data) > 1 and np.std(data) > 1e-8:\n",
    "        features[f'{prefix}_skew'] = pd.Series(data).skew()\n",
    "        features[f'{prefix}_kurt'] = pd.Series(data).kurtosis()\n",
    "    else:\n",
    "        features[f'{prefix}_skew'] = 0\n",
    "        features[f'{prefix}_kurt'] = 0\n",
    "    \n",
    "    # Differential features (capture dynamics)\n",
    "    if len(data) > 1:\n",
    "        diff_data = np.diff(data)\n",
    "        features[f'{prefix}_diff_mean'] = np.mean(diff_data)\n",
    "        features[f'{prefix}_diff_std'] = np.std(diff_data)\n",
    "        features[f'{prefix}_n_changes'] = np.sum(np.abs(diff_data) > np.std(data) * 0.1)  # Significant changes\n",
    "    else:\n",
    "        features[f'{prefix}_diff_mean'] = 0\n",
    "        features[f'{prefix}_diff_std'] = 0\n",
    "        features[f'{prefix}_n_changes'] = 0\n",
    "    \n",
    "    # Correlation with time (trend detection)\n",
    "    if len(data) > 2:\n",
    "        time_indices = np.arange(len(data))\n",
    "        try:\n",
    "            corr_coef = np.corrcoef(time_indices, data)[0, 1]\n",
    "            features[f'{prefix}_time_corr'] = corr_coef if not np.isnan(corr_coef) else 0\n",
    "        except:\n",
    "            features[f'{prefix}_time_corr'] = 0\n",
    "    else:\n",
    "        features[f'{prefix}_time_corr'] = 0\n",
    "    \n",
    "    # Segment features (beginning, middle, end patterns)\n",
    "    seq_len = len(data)\n",
    "    if seq_len >= 9:  # Need sufficient data for meaningful segments\n",
    "        seg_size = seq_len // 3\n",
    "        seg1 = data[:seg_size]           # Beginning (Transition phase)\n",
    "        seg2 = data[seg_size:2*seg_size] # Middle (Pause phase)  \n",
    "        seg3 = data[2*seg_size:]         # End (Gesture phase)\n",
    "        \n",
    "        features[f'{prefix}_seg1_mean'] = np.mean(seg1)\n",
    "        features[f'{prefix}_seg2_mean'] = np.mean(seg2)\n",
    "        features[f'{prefix}_seg3_mean'] = np.mean(seg3)\n",
    "        \n",
    "        features[f'{prefix}_seg1_std'] = np.std(seg1)\n",
    "        features[f'{prefix}_seg2_std'] = np.std(seg2)\n",
    "        features[f'{prefix}_seg3_std'] = np.std(seg3)\n",
    "        \n",
    "        # Segment transitions (important for distinguishing gesture types)\n",
    "        features[f'{prefix}_seg1_to_seg2'] = np.mean(seg2) - np.mean(seg1)\n",
    "        features[f'{prefix}_seg2_to_seg3'] = np.mean(seg3) - np.mean(seg2)\n",
    "    else:\n",
    "        # Not enough data for meaningful segments\n",
    "        for seg in [1, 2, 3]:\n",
    "            features[f'{prefix}_seg{seg}_mean'] = features[f'{prefix}_mean']\n",
    "            features[f'{prefix}_seg{seg}_std'] = features[f'{prefix}_std']\n",
    "        features[f'{prefix}_seg1_to_seg2'] = 0\n",
    "        features[f'{prefix}_seg2_to_seg3'] = 0\n",
    "\n",
    "    if len(data) > 1:\n",
    "        series = pd.Series(data)\n",
    "\n",
    "        # Peak detection - count significant changes\n",
    "        features[f\"{prefix}_peak_count\"] = (series.diff().abs() > (series.std() * 0.5)).sum()\n",
    "\n",
    "        # Movement intensity - mean absolute deviation (MAD)\n",
    "        features[f\"{prefix}_mad\"] = (series - series.mean()).abs().mean()\n",
    "\n",
    "        # Range normalization - signal range relative to std\n",
    "        features[f\"{prefix}_range_norm\"] = (series.max() - series.min()) / (series.std() + 1e-8)\n",
    "\n",
    "        # Acceleration analysis - second derivative\n",
    "        accel = series.diff().diff()\n",
    "        features[f\"{prefix}_accel_mean\"] = accel.abs().mean()\n",
    "        features[f\"{prefix}_accel_std\"] = accel.std()\n",
    "\n",
    "        # Movement consistency - coefficient of variation (CV)\n",
    "        features[f\"{prefix}_cv\"] = series.std() / (abs(series.mean()) + 1e-8)\n",
    "\n",
    "        # Energy measure - sum of squared values\n",
    "        features[f\"{prefix}_energy\"] = (series ** 2).sum()\n",
    "    else:\n",
    "        features[f\"{prefix}_peak_count\"] = 0\n",
    "        features[f\"{prefix}_mad\"] = 0\n",
    "        features[f\"{prefix}_range_norm\"] = 0\n",
    "        features[f\"{prefix}_accel_mean\"] = 0\n",
    "        features[f\"{prefix}_accel_std\"] = 0\n",
    "        features[f\"{prefix}_cv\"] = 0\n",
    "        features[f\"{prefix}_energy\"] = 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f8e19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.893774Z",
     "iopub.status.busy": "2025-10-19T08:25:15.893346Z",
     "iopub.status.idle": "2025-10-19T08:25:15.902674Z",
     "shell.execute_reply": "2025-10-19T08:25:15.901592Z"
    },
    "papermill": {
     "duration": 0.017162,
     "end_time": "2025-10-19T08:25:15.904558",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.887396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prediction_function(models, feature_cols, imu_cols):\n",
    "    \"\"\"Create prediction function for Kaggle evaluation\"\"\"\n",
    "    \n",
    "    def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Prediction function for Kaggle evaluation\n",
    "        Uses ensemble of trained LightGBM models\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Filter sequence to only include IMU columns that we trained with\n",
    "            available_cols = sequence.columns\n",
    "            sequence_imu_cols = [col for col in imu_cols if col in available_cols]\n",
    "            sequence_filtered = sequence.select(pl.col(sequence_imu_cols))\n",
    "            \n",
    "            # Extract features using the same method as training\n",
    "            features = extract_comprehensive_features(sequence_filtered, demographics)\n",
    "            \n",
    "            # Ensure we have the same features as training\n",
    "            missing_features = [col for col in feature_cols if col not in features.columns]\n",
    "            if missing_features:\n",
    "                print(f\"Warning: Missing features {missing_features}, filling with zeros\")\n",
    "                for col in missing_features:\n",
    "                    features[col] = 0\n",
    "            \n",
    "            X_pred = features[feature_cols]\n",
    "            print(X_pred)\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            # predictions = []\n",
    "            # for model in models:\n",
    "            #     pred_probs = model.predict_proba(X_pred)\n",
    "            #     pred_class = np.argmax(pred_probs, axis=1)[0]\n",
    "            #     predictions.append(pred_class)\n",
    "            \n",
    "            # # Ensemble prediction (majority vote)\n",
    "            # final_prediction = max(set(predictions), key=predictions.count)\n",
    "            \n",
    "            # # Convert back to gesture name\n",
    "            # gesture_name = REVERSE_GESTURE_MAPPER[final_prediction]\n",
    "            probs_all = []\n",
    "            for model in models:\n",
    "                pred_probs = model.predict_proba(X_pred)\n",
    "                probs_all.append(pred_probs[0])  # each is shape (num_classes,)\n",
    "            \n",
    "            # Convert to numpy array for averaging\n",
    "            probs_all = np.array(probs_all)  # shape: (n_models, n_classes)\n",
    "            \n",
    "            # 🔥 Soft voting: average probabilities across models\n",
    "            probs_mean = np.mean(probs_all, axis=0)\n",
    "            \n",
    "            # Final predicted class\n",
    "            final_prediction = int(np.argmax(probs_mean))\n",
    "            \n",
    "            # Convert back to gesture name\n",
    "            gesture_name = REVERSE_GESTURE_MAPPER[final_prediction]\n",
    "            \n",
    "            print(f\"Predicted: {gesture_name} (class {final_prediction})\")\n",
    "            return gesture_name\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return 'Text on phone'  # Fallback prediction\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8bc915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.915670Z",
     "iopub.status.busy": "2025-10-19T08:25:15.915308Z",
     "iopub.status.idle": "2025-10-19T08:25:15.923092Z",
     "shell.execute_reply": "2025-10-19T08:25:15.921561Z"
    },
    "papermill": {
     "duration": 0.016381,
     "end_time": "2025-10-19T08:25:15.925554",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.909173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_prediction_function(\n",
    "#     models,\n",
    "#     feature_cols,\n",
    "#     imu_cols,\n",
    "#     lstm_model_paths,     # list of 5 model paths\n",
    "#     prep_paths,           # list of 5 prep paths\n",
    "#     device,\n",
    "#     model_cls=IMUCrossAttentionModel\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Create prediction function for hybrid XGBoost + 5-Fold LSTM ensemble.\n",
    "#     \"\"\"\n",
    "\n",
    "#     import torch\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "#     import polars as pl\n",
    "#     import joblib\n",
    "\n",
    "#     # === Load all 5 LSTM models + preprocessors ===\n",
    "#     lstm_models = []\n",
    "#     for model_path, prep_path in zip(lstm_model_paths, prep_paths):\n",
    "#         prep = joblib.load(prep_path)\n",
    "#         # scaler = prep[\"transformer\"]\n",
    "#         pad_len = prep[\"max_length\"]\n",
    "#         n_classes = len(prep[\"categories\"])\n",
    "#         imu_features = prep[\"features\"]\n",
    "\n",
    "#         model = model_cls(len(imu_features), n_classes).to(device)\n",
    "#         model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "#         model.eval()\n",
    "#         lstm_models.append((model, pad_len, imu_features))\n",
    "\n",
    "#     # === Define the predict function ===\n",
    "#     def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#         try:\n",
    "#             # === 1️⃣ Extract static features ===\n",
    "#             available_cols = sequence.columns\n",
    "#             sequence_imu_cols = [col for col in imu_cols if col in available_cols]\n",
    "#             sequence_filtered = sequence.select(pl.col(sequence_imu_cols))\n",
    "#             static_features = extract_comprehensive_features(sequence_filtered, demographics)\n",
    "\n",
    "#             # === 2️⃣ Get embeddings from all 5 LSTM folds ===\n",
    "#             embeddings = []\n",
    "#             for model, pad_len, imu_features in lstm_models:\n",
    "#                 # Convert to pandas for preprocessing\n",
    "#                 df_seq = sequence_filtered.to_pandas()\n",
    "#                 df_seq = preprocess_left_handed_pd(df_seq, demographics)\n",
    "#                 df_seq = add_features(df_seq)\n",
    "\n",
    "#                 # Scale and pad\n",
    "#                 # df_seq.loc[:, imu_features] = scaler.transform(df_seq[imu_features])\n",
    "#                 X_seq = pad_sequences([df_seq[imu_features].to_numpy()], maxlen=pad_len)\n",
    "#                 X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "#                 # Extract embeddings\n",
    "#                 with torch.no_grad():\n",
    "#                     emb = model.extract_features(X_seq_tensor).cpu().numpy().flatten()\n",
    "#                 embeddings.append(emb)\n",
    "\n",
    "#             # Average embeddings across folds\n",
    "#             emb_mean = np.mean(embeddings, axis=0)\n",
    "#             emb_df = pd.DataFrame([emb_mean], columns=[f\"emb_{i}\" for i in range(len(emb_mean))])\n",
    "\n",
    "#             # === 3️⃣ Merge static + embedding features ===\n",
    "#             # Select static features used in training\n",
    "#             # X_pred = static_features[feature_cols]\n",
    "\n",
    "#             # # 🔹 Add embeddings to X_pred\n",
    "#             # X_pred = pd.concat([X_pred.reset_index(drop=True), emb_df.reset_index(drop=True)], axis=1)\n",
    "#             X_pred = pd.DataFrame(columns=feature_cols)\n",
    "#             # create one row of zeros\n",
    "#             X_pred.loc[0] = 0.0\n",
    "\n",
    "#             # Fill in static features (if present)\n",
    "#             # static_features is a DataFrame with one row\n",
    "#             for col in static_features.columns:\n",
    "#                 if col in X_pred.columns:\n",
    "#                     # take first element (static_features is per-sequence)\n",
    "#                     try:\n",
    "#                         X_pred.at[0, col] = static_features[col].iloc[0]\n",
    "#                     except Exception:\n",
    "#                         # fallback if static_features has scalar or different layout\n",
    "#                         X_pred.at[0, col] = static_features[col].values[0]\n",
    "\n",
    "#             # Fill embedding columns (emb_df is one-row)\n",
    "#             for col in emb_df.columns:\n",
    "#                 if col in X_pred.columns:\n",
    "#                     X_pred.at[0, col] = emb_df[col].iloc[0]\n",
    "#                 else:\n",
    "#                     # if embedding columns are not in feature_cols (shouldn't happen),\n",
    "#                     # add them (optional)\n",
    "#                     X_pred[col] = emb_df[col].iloc[0]\n",
    "\n",
    "#             # Now X_pred has exact columns and order as feature_cols (plus possibly extra emb cols)\n",
    "#             # If you want to force exact ordering and drop any extras:\n",
    "#             X_pred = X_pred[[c for c in feature_cols if c in X_pred.columns]]\n",
    "\n",
    "\n",
    "#             # === 4️⃣ Predict with XGBoost ensemble ===\n",
    "#             preds = []\n",
    "#             for m in models:\n",
    "#                 probs = m.predict_proba(X_pred)\n",
    "#                 preds.append(np.argmax(probs, axis=1)[0])\n",
    "\n",
    "#             final_pred = max(set(preds), key=preds.count)\n",
    "#             gesture_name = REVERSE_GESTURE_MAPPER[final_pred]\n",
    "\n",
    "#             print(f\"Predicted: {gesture_name} (class {final_pred})\")\n",
    "#             return gesture_name\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Prediction error: {e}\")\n",
    "#             import traceback\n",
    "#             traceback.print_exc()\n",
    "#             return \"Text on phone\"  # fallback\n",
    "\n",
    "#     return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1deb9c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T08:25:15.936279Z",
     "iopub.status.busy": "2025-10-19T08:25:15.935860Z",
     "iopub.status.idle": "2025-10-19T08:25:19.187840Z",
     "shell.execute_reply": "2025-10-19T08:25:19.186116Z"
    },
    "papermill": {
     "duration": 3.259457,
     "end_time": "2025-10-19T08:25:19.189789",
     "exception": false,
     "start_time": "2025-10-19T08:25:15.930332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Models ready for inference\n",
      "\n",
      "Setting up inference server...\n",
      "   sequence_length  age  adult_child  sex  handedness  height_cm  \\\n",
      "0               56   13            0    0           1      177.0   \n",
      "\n",
      "   shoulder_to_wrist_cm  elbow_to_wrist_cm  acc_x_mean  acc_x_std  ...  \\\n",
      "0                    52               27.0    7.750837   1.041217  ...   \n",
      "\n",
      "   acc_world_diff_seg3_std  acc_world_diff_seg1_to_seg2  \\\n",
      "0             2.580307e-15                 1.973730e-16   \n",
      "\n",
      "   acc_world_diff_seg2_to_seg3  acc_world_diff_peak_count  acc_world_diff_mad  \\\n",
      "0                -5.921189e-17                         34        2.383581e-15   \n",
      "\n",
      "   acc_world_diff_range_norm  acc_world_diff_accel_mean  \\\n",
      "0                   0.000001               4.671161e-15   \n",
      "\n",
      "   acc_world_diff_accel_std  acc_world_diff_cv  acc_world_diff_energy  \n",
      "0              6.230048e-15       2.828295e-07           5.301145e-28  \n",
      "\n",
      "[1 rows x 764 columns]\n",
      "Predicted: Eyebrow - pull hair (class 2)\n",
      "   sequence_length  age  adult_child  sex  handedness  height_cm  \\\n",
      "0               51   25            1    1           1      165.0   \n",
      "\n",
      "   shoulder_to_wrist_cm  elbow_to_wrist_cm  acc_x_mean  acc_x_std  ...  \\\n",
      "0                    52               23.0    -2.42379   3.499938  ...   \n",
      "\n",
      "   acc_world_diff_seg3_std  acc_world_diff_seg1_to_seg2  \\\n",
      "0             2.364375e-15                          0.0   \n",
      "\n",
      "   acc_world_diff_seg2_to_seg3  acc_world_diff_peak_count  acc_world_diff_mad  \\\n",
      "0                          0.0                         42        1.581716e-15   \n",
      "\n",
      "   acc_world_diff_range_norm  acc_world_diff_accel_mean  \\\n",
      "0               8.881782e-07               4.205253e-15   \n",
      "\n",
      "   acc_world_diff_accel_std  acc_world_diff_cv  acc_world_diff_energy  \n",
      "0              5.036830e-15       1.919007e-07           2.398137e-28  \n",
      "\n",
      "[1 rows x 764 columns]\n",
      "Predicted: Eyelash - pull hair (class 3)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    lstm_model_paths = [f\"{Config.EXPORT_DIR}/model_best_fold_{i}.pt\" for i in range(1, 5)]\n",
    "    prep_paths = [f\"{Config.EXPORT_DIR}/prep_fold_{i}.joblib\" for i in range(1, 5)]\n",
    "    model = joblib.load(\"/kaggle/input/xgboost1/xgb_model.pkl\")\n",
    "    feature_cols = joblib.load(\"/kaggle/input/xgboost1/feature_cols.pkl\")\n",
    "    imu_cols = joblib.load(\"/kaggle/input/xgboost1/imu_cols.pkl\")\n",
    "\n",
    "    for m in model:\n",
    "        if hasattr(m, \"get_booster\"):   # XGBClassifier / XGBRegressor wrapper\n",
    "            m.get_booster().set_param({\"device\": \"cpu\"})\n",
    "        elif hasattr(m, \"set_param\"):   # raw Booster\n",
    "            m.set_param({\"device\": \"cpu\"})\n",
    "        elif hasattr(m, \"set_params\"):  # sklearn-style wrapper\n",
    "            m.set_params(device=\"cpu\")\n",
    "    \n",
    "    # Create prediction function\n",
    "    # predict_func = create_prediction_function(model, feature_cols, imu_cols, lstm_model_paths, prep_paths,\"cpu\")\n",
    "    predict_func = create_prediction_function(model, feature_cols, imu_cols)\n",
    "\n",
    "    print(f\"✓ Models ready for inference\")\n",
    "    \n",
    "    return predict_func, model\n",
    "\n",
    "# Execute main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    predict_function, trained_models = main()\n",
    "    \n",
    "    # Setup inference server\n",
    "    print(\"\\nSetting up inference server...\")\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict_function)\n",
    "    \n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # if 0 :\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        # Local testing\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                Config.TEST_PATH,\n",
    "                Config.TEST_DEMOGRAPHICS_PATH,\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 14144301,
     "datasetId": 8520152,
     "sourceId": 13429751,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 14145898,
     "datasetId": 8160735,
     "sourceId": 13431205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.94386,
   "end_time": "2025-10-19T08:25:22.205493",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-19T08:24:51.261633",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
